#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª:
1. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ØŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø³ÙØ§Ø±Ø´Ø§Øª Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
2. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Matomo Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ parquet Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
3. Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
4. Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªÙˆØµÛŒÙ‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
5. Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ parquet Ùˆ Redis Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""
from __future__ import annotations
import datetime as dt
import glob
import logging
import os
import gc
from collections import defaultdict
from pathlib import Path
from typing import List, Dict, Optional

import numpy as np
import polars as pl
from sqlalchemy import text

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

from dataframe_loader import get_engine, load_order_items
from hybrid_recommender import HybridRecommender
from models import Product, ProductInteraction, User
from object_loader import load_products, load_users
from settings import load_config

# ØªÙ†Ø¸ÛŒÙ… logger
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_users_from_db() -> pl.DataFrame:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª DataFrame Ø¨Ø§ retry logic"""
    from dataframe_loader import get_engine, reset_engine
    import time
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            engine = get_engine(force_new=(attempt > 0))
            sql = text("""
                SELECT id, email, 
                       CONCAT(COALESCE(first_name, ''), ' ', COALESCE(last_name, '')) as name,
                       created_at
                FROM users
                ORDER BY id
            """)
            
            with engine.connect() as conn:
                rows = [dict(row) for row in conn.execute(sql).mappings()]
            
            if not rows:
                return pl.DataFrame()
            
            return pl.DataFrame(rows)
        except Exception as e:
            if "Packet sequence" in str(e) or "InternalError" in str(e):
                if attempt < max_retries - 1:
                    logger.warning(f"Database connection error (attempt {attempt + 1}/{max_retries}), resetting connection...")
                    reset_engine()
                    time.sleep(1)
                    continue
                else:
                    logger.error(f"Failed to connect after {max_retries} attempts")
                    raise
            else:
                raise


def load_products_from_db() -> pl.DataFrame:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª DataFrame Ø¨Ø§ retry logic"""
    from dataframe_loader import get_engine, reset_engine
    import time
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            engine = get_engine(force_new=(attempt > 0))
            sql = text("""
                SELECT id, title, slug, sku, sale_price, stock_quantity, 
                       status, published_at, seller_id, category_id
                FROM products
                WHERE deleted_at IS NULL AND status = 1
                ORDER BY id
            """)
            
            with engine.connect() as conn:
                rows = [dict(row) for row in conn.execute(sql).mappings()]
            
            if not rows:
                return pl.DataFrame()
            
            return pl.DataFrame(rows)
        except Exception as e:
            if "Packet sequence" in str(e) or "InternalError" in str(e):
                if attempt < max_retries - 1:
                    logger.warning(f"Database connection error (attempt {attempt + 1}/{max_retries}), resetting connection...")
                    reset_engine()
                    time.sleep(1)
                    continue
                else:
                    logger.error(f"Failed to connect after {max_retries} attempts")
                    raise
            else:
                raise


def create_user_product_interactions(order_items_df: pl.DataFrame) -> List[ProductInteraction]:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù„ÛŒØ³Øª ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª"""
    interactions = []
    
    if order_items_df.is_empty():
        return interactions
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹â€ŒØªØ±
    for row in order_items_df.iter_rows(named=True):
        interaction = ProductInteraction(
            user_id=row['order_user_id'],
            product_id=row['product_id'],
            interaction_type='purchase',
            timestamp=row['order_created_at'],
            value=float(row['total_price'])
        )
        interactions.append(interaction)
    
    logger.info(f"Extracted {len(interactions)} purchase interactions")
    return interactions


def load_matomo_product_popularity() -> Dict[int, float]:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Matomo"""
    cfg = load_config()
    pageviews_files = sorted(glob.glob(
        os.path.join(cfg.output_dir, "matomo_pageviews_*.parquet")
    ))
    
    if not pageviews_files:
        logger.warning("Matomo pageviews file not found")
        return {}
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„
    latest_file = pageviews_files[-1]
    df = pl.read_parquet(latest_file)
    
    product_popularity = {}
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØµÙØ­Ø§Øª Ù…Ø­ØµÙˆÙ„ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª
    if 'label' in df.columns and 'nb_visits' in df.columns:
        product_rows = df.filter(pl.col('label') == 'product')
        
        for row in product_rows.iter_rows(named=True):
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ product_id Ø§Ø² URL ÛŒØ§ label
            # Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± URLâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø¯Ø§Ø±Ø¯
            # ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ú©Ù„ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
            popularity_score = float(row['nb_visits'])
            product_popularity[0] = popularity_score  # Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
    
    logger.info("Matomo popularity data loaded")
    return product_popularity


def generate_recommendations_for_users(
    recommender: HybridRecommender,
    user_ids: List[int],
    top_k: int = 20
) -> pl.DataFrame:
    """
    ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ù…Ø´Ø®ØµÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    
    Args:
        recommender: Ù…Ø¯Ù„ ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø± (Ø¨Ø§ÛŒØ¯ Ù‚Ø¨Ù„Ø§Ù‹ train Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)
        user_ids: Ù„ÛŒØ³Øª ID Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        top_k: ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        
    Returns:
        DataFrame Ø´Ø§Ù…Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    """
    if not user_ids:
        logger.warning("No user IDs provided")
        return pl.DataFrame()
    
    recommendations_data = []
    
    logger.info(f"Starting recommendation generation for {len(user_ids)} specific users...")
    
    # Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
    total_users = len(user_ids)
    users_with_recommendations = 0
    users_without_recommendations = 0
    
    for idx, user_id in enumerate(user_ids, 1):
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
        if idx % 10 == 0 or idx == total_users:
            logger.info(f"Processing user {idx}/{total_users} (User ID: {user_id})...")
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            recommendations = recommender.get_recommendations(user_id, top_k)
            
            if recommendations:
                users_with_recommendations += 1
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª
                for rank, rec in enumerate(recommendations, 1):
                    recommendations_data.append({
                        'user_id': user_id,
                        'product_id': rec.product_id,
                        'score': rec.score,
                        'rank': rank,
                        'confidence': rec.confidence,
                        'reason': rec.reason,
                        'collaborative_details': rec.collaborative_details,
                        'generated_at': dt.datetime.now()
                    })
            else:
                users_without_recommendations += 1
                logger.debug(f"No recommendations for user {user_id}")
                
        except Exception as e:
            users_without_recommendations += 1
            logger.warning(f"Error for user {user_id}: {e}")
    
    logger.info(
        f"Summary: {users_with_recommendations} users with recommendations, "
        f"{users_without_recommendations} without. "
        f"Total recommendations: {len(recommendations_data)}"
    )
    
    if not recommendations_data:
        logger.error("No recommendations generated!")
        return pl.DataFrame()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    recommendations_df = pl.DataFrame(recommendations_data)
    
    return recommendations_df


def generate_recommendations_for_all_users(
    recommender: HybridRecommender,
    users_df: pl.DataFrame,
    top_k: int = 20,
    sample_size: int = None
) -> pl.DataFrame:
    """
    ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    
    Args:
        recommender: Ù…Ø¯Ù„ ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø±
        users_df: DataFrame Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        top_k: ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        sample_size: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (None = Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†)
    """
    
    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ sample Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
    if sample_size and sample_size < len(users_df):
        users_df = users_df.head(sample_size)
        logger.warning(f"Test mode: Only processing first {sample_size} users")
    
    recommendations_data = []
    
    logger.info(f"Starting recommendation generation for {len(users_df)} users...")
    
    # Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
    total_users = len(users_df)
    users_with_recommendations = 0
    users_without_recommendations = 0
    
    for idx, row in enumerate(users_df.iter_rows(named=True), 1):
        user_id = row['id']
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
        if idx % 100 == 0 or idx == total_users:
            logger.info(f"Processing user {idx}/{total_users} (User ID: {user_id})...")
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            recommendations = recommender.get_recommendations(user_id, top_k)
            
            if recommendations:
                users_with_recommendations += 1
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª
                for rank, rec in enumerate(recommendations, 1):
                    recommendations_data.append({
                        'user_id': user_id,
                        'product_id': rec.product_id,
                        'score': rec.score,
                        'rank': rank,
                        'confidence': rec.confidence,
                        'reason': rec.reason,
                        'collaborative_details': rec.collaborative_details,
                        'generated_at': dt.datetime.now()
                    })
            else:
                users_without_recommendations += 1
                
        except Exception as e:
            users_without_recommendations += 1
            if idx <= 10:  # ÙÙ‚Ø· 10 Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
                logger.warning(f"Error for user {user_id}: {e}")
    
    logger.info(
        f"Summary: {users_with_recommendations} users with recommendations, "
        f"{users_without_recommendations} without. "
        f"Total recommendations: {len(recommendations_data)}"
    )
    
    if not recommendations_data:
        logger.error("No recommendations generated!")
        return pl.DataFrame()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    recommendations_df = pl.DataFrame(recommendations_data)
    
    return recommendations_df


def save_recommendations(recommendations_df: pl.DataFrame, output_dir: str) -> str:
    """Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ parquet"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"user_recommendations_{timestamp}.parquet")
    
    recommendations_df.write_parquet(output_file)
    logger.info(f"Recommendations saved to: {output_file}")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø³Ø®Ù‡ CSV Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø­Øªâ€ŒØªØ±
    csv_file = output_file.replace('.parquet', '.csv')
    recommendations_df.write_csv(csv_file)
    logger.info(f"CSV version saved to: {csv_file}")
    
    return output_file


def print_sample_recommendations(recommendations_df: pl.DataFrame, products_df: pl.DataFrame, n_users: int = 5):
    """Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
    if recommendations_df.is_empty():
        return
    
    # ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹
    products_dict = {}
    for row in products_df.iter_rows(named=True):
        products_dict[row['id']] = row['title']
    
    print(f"\n{'='*80}")
    print(f"Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {n_users} Ú©Ø§Ø±Ø¨Ø± Ø§ÙˆÙ„:")
    print(f"{'='*80}\n")
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ user_id
    unique_users = recommendations_df['user_id'].unique().sort()[:n_users]
    
    for user_id in unique_users:
        user_recs = recommendations_df.filter(pl.col('user_id') == user_id).sort('rank')
        
        print(f"Ú©Ø§Ø±Ø¨Ø± {user_id} - {len(user_recs)} ØªÙˆØµÛŒÙ‡:")
        print("-" * 80)
        
        # Ù†Ù…Ø§ÛŒØ´ 5 ØªÙˆØµÛŒÙ‡ Ø§ÙˆÙ„
        for row in user_recs.head(5).iter_rows(named=True):
            product_title = products_dict.get(row['product_id'], f"Ù…Ø­ØµÙˆÙ„ {row['product_id']}")
            print(f"  {row['rank']}. {product_title}")
            print(f"     Ø§Ù…ØªÛŒØ§Ø²: {row['score']:.4f} | Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {row['confidence']:.2f}")
            print(f"     Ø¯Ù„ÛŒÙ„: {row['reason'][:100]}...")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª collaborative Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            if 'collaborative_details' in row and row['collaborative_details']:
                print(f"     Ø¬Ø²Ø¦ÛŒØ§Øª: {row['collaborative_details'][:150]}...")
        
        print()


def get_memory_usage_mb() -> float:
    """Get current memory usage in MB"""
    if not PSUTIL_AVAILABLE:
        return 0.0
    try:
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024 / 1024
    except:
        return 0.0

def log_memory_usage(stage: str):
    """Log memory usage at a specific stage"""
    if PSUTIL_AVAILABLE:
        mem_mb = get_memory_usage_mb()
        print(f"   ğŸ’¾ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ ({stage}): {mem_mb:.1f} MB")
        return mem_mb
    return 0.0

def main(sample_size: int = None):
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
    
    Args:
        sample_size: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (None = Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†)
    """
    print("="*80)
    print("Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª")
    if sample_size:
        print(f"ğŸ§ª Ø­Ø§Ù„Øª ØªØ³Øª - {sample_size} Ú©Ø§Ø±Ø¨Ø±")
    else:
        print("ğŸš€ Ø­Ø§Ù„Øª Ú©Ø§Ù…Ù„ - Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†")
    print("="*80)
    print()
    
    cfg = load_config()
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    print("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    initial_memory = log_memory_usage("Ø´Ø±ÙˆØ¹")
    users_df = load_users_from_db()
    if users_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    print(f"âœ… {len(users_df)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    log_memory_usage("Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†")
    
    # 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    products_df = load_products_from_db()
    if products_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    print(f"âœ… {len(products_df)} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    log_memory_usage("Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª")
    
    # 3. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª (Ø¢Ø®Ø± 180 Ø±ÙˆØ²)
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    end_date = dt.date.today()
    start_date = end_date - dt.timedelta(days=180)  # 6 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡
    
    order_items_df = load_order_items(start_date, end_date)
    if order_items_df.is_empty():
        print("âš ï¸  Ù‡ÛŒÚ† Ø³ÙØ§Ø±Ø´ÛŒ Ø¯Ø± 180 Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        print("   ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø³ÙØ§Ø±Ø´Ø§Øª...")
        # Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªÙ…Ø§Ù… Ø³ÙØ§Ø±Ø´Ø§Øª Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒÙ…
        start_date = dt.date(2020, 1, 1)
        order_items_df = load_order_items(start_date, end_date)
        
        if order_items_df.is_empty():
            print("âŒ Ù‡ÛŒÚ† Ø³ÙØ§Ø±Ø´ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯! Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø§Ø±Ø¯.")
            return
    
    print(f"âœ… {len(order_items_df)} Ø¢ÛŒØªÙ… Ø³ÙØ§Ø±Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    print(f"   Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {start_date} ØªØ§ {end_date}")
    
    # 4. Ø§ÛŒØ¬Ø§Ø¯ ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„
    print("\nğŸ”„ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„...")
    interactions = create_user_product_interactions(order_items_df)
    
    if not interactions:
        print("âŒ Ù‡ÛŒÚ† ØªØ¹Ø§Ù…Ù„ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯!")
        return
    
    # 5. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Matomo (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ø§Ø² Matomo...")
    matomo_popularity = load_matomo_product_popularity()
    
    # 6. ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ø¨Ù‡ ØµÙˆØ±Øª lazy Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡)
    print("\nğŸ”„ ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§...")
    
    # ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ù†Ù‡ Ù‡Ù…Ù‡)
    # Ø¨Ø±Ø§ÛŒ content-based ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± ØªØ¹Ø§Ù…Ù„Ø§Øª Ù‡Ø³ØªÙ†Ø¯
    products_in_interactions = set()
    for interaction in interactions:
        products_in_interactions.add(interaction.product_id)
    
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¯Ø± ØªØ¹Ø§Ù…Ù„Ø§Øª: {len(products_in_interactions)}")
    
    # ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    products_list = []
    products_dict = {}  # Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø±ÛŒØ¹
    for row in products_df.iter_rows(named=True):
        product_id = row['id']
        if product_id in products_in_interactions:
            from models import Product
            product = Product(
                id=product_id,
                title=row['title'],
                slug=row['slug'],
                sku=row['sku'],
                sale_price=float(row['sale_price'] or 0),
                stock_quantity=int(row['stock_quantity'] or 0),
                status='published' if row['status'] == 1 else 'draft',
                published_at=row.get('published_at'),
                seller_id=row.get('seller_id'),
                category_id=row.get('category_id')
            )
            products_list.append(product)
            products_dict[product_id] = product
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† products_df Ø¨Ø±Ø§ÛŒ ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± ØªØ¹Ø§Ù…Ù„Ø§Øª Ù‡Ø³ØªÙ†Ø¯ (Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ)
    # Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    products_df = products_df.filter(pl.col('id').is_in(list(products_in_interactions)))
    
    import gc
    gc.collect()
    
    print(f"   âœ… {len(products_list)} Ù…Ø­ØµÙˆÙ„ Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ user_id (Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± users_df)
    user_interactions = defaultdict(list)
    for interaction in interactions:
        user_interactions[interaction.user_id].append(interaction)
    
    # Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª lazy Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ… (ÙÙ‚Ø· ID Ù‡Ø§)
    users_dict = {}
    for row in users_df.iter_rows(named=True):
        from models import User
        user = User(
            id=row['id'],
            email=row.get('email'),
            name=row.get('name'),
            created_at=row.get('created_at')
        )
        users_dict[user.id] = user
    
    print(f"   âœ… {len(users_dict)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† users_df Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø± generate_recommendations_for_all_users
    # Ø§Ù…Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ Ø¯Ø± ØªØ¹Ø§Ù…Ù„Ø§Øª Ù‡Ø³ØªÙ†Ø¯ (Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡)
    users_with_interactions = set(user_interactions.keys())
    if len(users_with_interactions) < len(users_df):
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† users_df Ø¨Ø±Ø§ÛŒ ÙÙ‚Ø· Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ ØªØ¹Ø§Ù…Ù„ Ø¯Ø§Ø±Ù†Ø¯
        users_df = users_df.filter(pl.col('id').is_in(list(users_with_interactions)))
        print(f"   âœ… ÙÛŒÙ„ØªØ± Ø´Ø¯ Ø¨Ù‡ {len(users_df)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ ØªØ¹Ø§Ù…Ù„")
    
    # Ø§Ú¯Ø± sample_size Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ØŒ ÙÙ‚Ø· Ù‡Ù…Ø§Ù† ØªØ¹Ø¯Ø§Ø¯ Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
    if sample_size and sample_size < len(users_df):
        users_df = users_df.head(sample_size)
        print(f"   âœ… Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯ Ø¨Ù‡ {len(users_df)} Ú©Ø§Ø±Ø¨Ø± (sample_size)")
    
    # 7. Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡
    print("\nğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡...")
    print("   Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯...")
    
    recommender = HybridRecommender()
    
    # ØªÙ†Ø¸ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ - ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø±ØªØ¨Ø·
    recommender.users = list(users_dict.values())
    recommender.products = products_list
    
    # user_interactions Ù‚Ø¨Ù„Ø§Ù‹ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡
    recommender.user_interactions = dict(user_interactions)
    
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ ØªØ¹Ø§Ù…Ù„: {len(user_interactions)}")
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    try:
        from collaborative_filtering import train_collaborative_model
        from content_based_filtering import train_content_based_model
        
        print("   ğŸ”¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Collaborative Filtering...")
        recommender.collaborative_model = train_collaborative_model(interactions)
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø§ØªØ±ÛŒØ³ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡
        if recommender.collaborative_model and recommender.collaborative_model.use_storage:
            if recommender.collaborative_model.user_item_matrix is not None:
                del recommender.collaborative_model.user_item_matrix
            if recommender.collaborative_model.user_similarities is not None:
                del recommender.collaborative_model.user_similarities
            gc.collect()
            print("   âœ… Ù…Ø§ØªØ±ÛŒØ³â€ŒÙ‡Ø§ Ø¯Ø± DuckDB Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ùˆ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ù¾Ø§Ú© Ø´Ø¯")
        
        print("   ğŸ”¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Content-Based Filtering...")
        recommender.content_model = train_content_based_model(products_list, user_interactions)
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø§Ø² Ø­Ø§ÙØ¸Ù‡
        if recommender.content_model:
            # Product features Ø¯Ø± storage Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ØŒ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ù¾Ø§Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            if hasattr(recommender.content_model, 'product_features'):
                del recommender.content_model.product_features
            gc.collect()
        
        print("âœ… Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯!")
        log_memory_usage("Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù…ÙˆØ²Ø´")
        
        # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        gc.collect()
        log_memory_usage("Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 8. ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    if sample_size:
        print(f"\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ {sample_size} Ú©Ø§Ø±Ø¨Ø± (Ù†Ù…ÙˆÙ†Ù‡ ØªØ³Øª)...")
    else:
        print("\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†...")
    
    recommendations_df = generate_recommendations_for_all_users(
        recommender,
        users_df,
        top_k=20,  # 20 ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        sample_size=sample_size
    )
    
    if recommendations_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯!")
        return
    
    # 9. Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print("\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§...")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ (backup)
    output_file = save_recommendations(recommendations_df, cfg.output_dir)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DuckDB (persistent storage)
    try:
        if recommender.storage:
            recommender.storage.save_recommendations_batch(recommendations_df, overwrite=True)
            duckdb_stats = recommender.storage.get_recommendations_stats()
            print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± DuckDB:")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {duckdb_stats['total_recommendations']:,}")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ ØªÙˆØµÛŒÙ‡: {duckdb_stats['users_with_recommendations']:,}")
            if duckdb_stats.get('last_generated_at'):
                print(f"   Ø¢Ø®Ø±ÛŒÙ† ØªÙˆÙ„ÛŒØ¯: {duckdb_stats['last_generated_at']}")
        else:
            print("âš ï¸  ModelStorage Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± DuckDB Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ DuckDB: {e}")
        import traceback
        traceback.print_exc()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis (cache)
    try:
        from recommendation_storage import get_storage
        storage = get_storage()
        
        if storage.test_connection():
            stats = storage.store_batch_from_dataframe(recommendations_df, batch_size=1000)
            storage_stats = storage.get_stats()
            print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Redis (Cache):")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡: {storage_stats['total_recommendations']}")
            print(f"   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡: {storage_stats['memory_usage_mb']} MB")
        else:
            print("âš ï¸  Redis Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ÙÙ‚Ø· DuckDB Ùˆ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except ImportError:
        print("âš ï¸  Ù…Ø§Ú˜ÙˆÙ„ recommendation_storage Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ - ÙÙ‚Ø· DuckDB Ùˆ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Redis: {e}")
        print("   âœ… DuckDB Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
    
    # 10. Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ products_df (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§)
    try:
        _ = len(products_df)
    except (NameError, UnboundLocalError):
        # Ø§Ú¯Ø± products_df ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´)
        print("âš ï¸  Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ø¯Ø¯ products_df Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´...")
        products_df = load_products_from_db()
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙÙ‚Ø· Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø±ØªØ¨Ø·
        products_in_interactions = set()
        for interaction in interactions:
            products_in_interactions.add(interaction.product_id)
        if products_in_interactions:
            products_df = products_df.filter(pl.col('id').is_in(list(products_in_interactions)))
    
    print_sample_recommendations(recommendations_df, products_df, n_users=5)
    
    # 11. Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
    print(f"\n{'='*80}")
    print("âœ… ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"{'='*80}")
    print(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {len(users_df)}")
    try:
        print(f"   ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products_df)}")
    except (NameError, UnboundLocalError):
        print(f"   ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: N/A")
    try:
        print(f"   ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´Ø§Øª: {len(order_items_df)}")
    except (NameError, UnboundLocalError):
        print(f"   ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´Ø§Øª: N/A")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {len(recommendations_df)}")
    print(f"   ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print(f"{'='*80}\n")


def main_for_specific_users(user_ids: List[int], top_k: int = 20):
    """
    ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ (Ø¨Ø¯ÙˆÙ† train Ú©Ø±Ø¯Ù† Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„)
    
    Args:
        user_ids: Ù„ÛŒØ³Øª ID Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        top_k: ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
    """
    print("="*80)
    print("Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª")
    print(f"ğŸ¯ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ - {len(user_ids)} Ú©Ø§Ø±Ø¨Ø±")
    print("="*80)
    print()
    
    cfg = load_config()
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ ØªØ¬Ø§Ø±ÛŒ)
    print("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    products_df = load_products_from_db()
    if products_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    print(f"âœ… {len(products_df)} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # 2. ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ Ù„ÛŒØ³Øª
    products_list = []
    for row in products_df.iter_rows(named=True):
        from models import Product
        product = Product(
            id=row['id'],
            title=row['title'],
            slug=row['slug'],
            sku=row['sku'],
            sale_price=float(row['sale_price'] or 0),
            stock_quantity=int(row['stock_quantity'] or 0),
            status='published' if row['status'] == 1 else 'draft',
            published_at=row.get('published_at'),
            seller_id=row.get('seller_id'),
            category_id=row.get('category_id')
        )
        products_list.append(product)
    
    # 3. Initialize recommender (Ø§Ø² storage Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
    print("\nğŸ”„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² storage...")
    print("   (Ù…Ø¯Ù„ Ø¨Ø§ÛŒØ¯ Ù‚Ø¨Ù„Ø§Ù‹ train Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)")
    
    recommender = HybridRecommender(use_storage=True)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ (Ø¨Ø¯ÙˆÙ† train Ú©Ø±Ø¯Ù†)
    recommender.users = load_users()
    recommender.products = products_list
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ)
    print(f"ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ {len(user_ids)} Ú©Ø§Ø±Ø¨Ø±...")
    # ÙÙ‚Ø· ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    recommender.user_interactions = {}
    from object_loader import load_user_purchase_history
    for user_id in user_ids:
        purchase_history = load_user_purchase_history(user_id, days_back=365)
        recommender.user_interactions[user_id] = purchase_history
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ train Ø´Ø¯Ù‡ Ø§Ø² storage
    try:
        from collaborative_filtering import CollaborativeFiltering
        from content_based_filtering import ContentBasedFiltering
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ collaborative model Ø§Ø² storage
        print("   ğŸ”¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Collaborative Filtering Ø§Ø² storage...")
        recommender.collaborative_model = CollaborativeFiltering(use_storage=True, storage=recommender.storage)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ mappings Ø§Ø² storage
        if recommender.storage:
            conn = recommender.storage._get_connection(read_only=True)
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ user mappings
            user_mappings = conn.execute("SELECT user_id, user_index FROM user_index_mapping").fetchall()
            recommender.collaborative_model.user_to_index = {row[0]: row[1] for row in user_mappings}
            recommender.collaborative_model.index_to_user = {row[1]: row[0] for row in user_mappings}
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ product mappings
            product_mappings = conn.execute("SELECT product_id, product_index FROM product_index_mapping").fetchall()
            recommender.collaborative_model.product_to_index = {row[0]: row[1] for row in product_mappings}
            recommender.collaborative_model.index_to_product = {row[1]: row[0] for row in product_mappings}
            
            logger.info(f"Loaded {len(recommender.collaborative_model.user_to_index)} user mappings and {len(recommender.collaborative_model.product_to_index)} product mappings")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ content-based model Ø§Ø² storage
        print("   ğŸ”¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Content-Based Filtering Ø§Ø² storage...")
        recommender.content_model = ContentBasedFiltering(use_storage=True, storage=recommender.storage)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ANN index
        if not recommender.content_model._load_ann_index():
            print("âš ï¸  ANN index ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø¯Ù„ Ù‡Ù†ÙˆØ² train Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.")
            print("   Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ù…Ø¯Ù„ Ø±Ø§ train Ú©Ù†ÛŒØ¯:")
            print("   python generate_recommendations.py --sample 100")
            return
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ user profiles Ø§Ø² storage (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
        if recommender.storage:
            try:
                conn = recommender.storage._get_connection(read_only=True)
                result = conn.execute("SELECT user_id, profile_data FROM user_profiles").fetchall()
                user_profiles = {}
                for row in result:
                    import pickle
                    user_profiles[row[0]] = pickle.loads(row[1])
                
                if user_profiles:
                    recommender.content_model.user_profiles = user_profiles
                    logger.info(f"Loaded {len(user_profiles)} user profiles from storage")
            except Exception as e:
                logger.warning(f"Could not load user profiles: {e}")
        
        print("âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² storage Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯!")
        
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² storage: {e}")
        import traceback
        traceback.print_exc()
        print("\n   Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø¯Ù„ Ù‡Ù†ÙˆØ² train Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ù…Ø¯Ù„ Ø±Ø§ train Ú©Ù†ÛŒØ¯:")
        print("   python generate_recommendations.py --sample 100")
        return
    
    # 4. ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ
    print(f"\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ {len(user_ids)} Ú©Ø§Ø±Ø¨Ø±...")
    
    recommendations_df = generate_recommendations_for_users(
        recommender,
        user_ids,
        top_k=top_k
    )
    
    if recommendations_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯!")
        return
    
    # 5. Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print("\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§...")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
    output_file = save_recommendations(recommendations_df, cfg.output_dir)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± DuckDB (persistent storage)
    try:
        if recommender.storage:
            recommender.storage.save_recommendations_batch(recommendations_df, overwrite=True)
            duckdb_stats = recommender.storage.get_recommendations_stats()
            print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± DuckDB:")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {duckdb_stats['total_recommendations']:,}")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ ØªÙˆØµÛŒÙ‡: {duckdb_stats['users_with_recommendations']:,}")
            if duckdb_stats.get('last_generated_at'):
                print(f"   Ø¢Ø®Ø±ÛŒÙ† ØªÙˆÙ„ÛŒØ¯: {duckdb_stats['last_generated_at']}")
        else:
            print("âš ï¸  ModelStorage Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± DuckDB Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ DuckDB: {e}")
        import traceback
        traceback.print_exc()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis (cache)
    try:
        from recommendation_storage import get_storage
        storage = get_storage()
        
        if storage.test_connection():
            stats = storage.store_batch_from_dataframe(recommendations_df, batch_size=1000)
            storage_stats = storage.get_stats()
            print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Redis (Cache):")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡: {storage_stats['total_recommendations']}")
            print(f"   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡: {storage_stats['memory_usage_mb']} MB")
        else:
            print("âš ï¸  Redis Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ÙÙ‚Ø· DuckDB Ùˆ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except ImportError:
        print("âš ï¸  Ù…Ø§Ú˜ÙˆÙ„ recommendation_storage Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ - ÙÙ‚Ø· DuckDB Ùˆ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Redis: {e}")
        print("   âœ… DuckDB Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
    
    # 6. Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print_sample_recommendations(recommendations_df, products_df, n_users=min(5, len(user_ids)))
    
    # 7. Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
    print(f"\n{'='*80}")
    print("âœ… ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"{'='*80}")
    print(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {len(user_ids)}")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products_df)}")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {len(recommendations_df)}")
    print(f"   ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print(f"{'='*80}\n")


def find_users_without_recommendations(limit: Optional[int] = None, output_file: Optional[str] = None) -> List[int]:
    """
    Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒØ´Ø§Ù† Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª
    
    Args:
        limit: Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ (None = Ù‡Ù…Ù‡)
        output_file: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
        
    Returns:
        Ù„ÛŒØ³Øª user_id Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡
    """
    print("="*80)
    print("Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡")
    print("="*80)
    print()
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    print("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    users_df = load_users_from_db()
    if users_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return []
    
    print(f"âœ… {len(users_df)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø§Ú¯Ø± limit Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
    if limit and limit < len(users_df):
        users_df = users_df.head(limit)
        print(f"âš ï¸  Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯ Ø¨Ù‡ {limit} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ")
    
    # 2. Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ØªÙˆØµÛŒÙ‡ Ø¯Ø± Redis
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Redis...")
    try:
        from recommendation_storage import get_storage
        storage = get_storage()
        
        if not storage.test_connection():
            print("âŒ Redis Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª!")
            return []
        
        print("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Redis Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯")
        
    except ImportError:
        print("âŒ Ù…Ø§Ú˜ÙˆÙ„ recommendation_storage Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        return []
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Redis: {e}")
        return []
    
    # 3. Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
    user_ids = users_df['id'].to_list()
    users_with_recommendations = []
    users_without_recommendations = []
    
    total_users = len(user_ids)
    print(f"\nğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ {total_users} Ú©Ø§Ø±Ø¨Ø±...")
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª batch
    batch_size = 100
    for i in range(0, len(user_ids), batch_size):
        batch = user_ids[i:i + batch_size]
        
        for user_id in batch:
            if storage.exists(user_id):
                users_with_recommendations.append(user_id)
            else:
                users_without_recommendations.append(user_id)
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
        checked = min(i + batch_size, total_users)
        if checked % 1000 == 0 or checked == total_users:
            print(f"   Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {checked}/{total_users} ({checked/total_users*100:.1f}%)")
    
    # 4. Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
    print(f"\n{'='*80}")
    print("ğŸ“Š Ù†ØªØ§ÛŒØ¬:")
    print(f"{'='*80}")
    print(f"   Ú©Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {total_users:,}")
    print(f"   Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ ØªÙˆØµÛŒÙ‡: {len(users_with_recommendations):,} ({len(users_with_recommendations)/total_users*100:.1f}%)")
    print(f"   Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡: {len(users_without_recommendations):,} ({len(users_without_recommendations)/total_users*100:.1f}%)")
    print(f"{'='*80}\n")
    
    # 5. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
    if output_file and users_without_recommendations:
        import os
        os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª CSV
        import polars as pl
        df = pl.DataFrame({'user_id': users_without_recommendations})
        df.write_csv(output_file)
        print(f"ğŸ’¾ Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_file}")
        
        # Ù‡Ù…Ú†Ù†ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ txt Ø³Ø§Ø¯Ù‡
        txt_file = output_file.replace('.csv', '.txt')
        with open(txt_file, 'w') as f:
            for user_id in users_without_recommendations:
                f.write(f"{user_id}\n")
        print(f"ğŸ’¾ Ù†Ø³Ø®Ù‡ TXT Ù†ÛŒØ² Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {txt_file}")
    
    return users_without_recommendations


if __name__ == "__main__":
    import sys
    import argparse
    
    # ØªÙ†Ø¸ÛŒÙ… CLI arguments
    parser = argparse.ArgumentParser(
        description="ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:
  # ØªØ³Øª Ø¨Ø§ 1000 Ú©Ø§Ø±Ø¨Ø±
  python generate_recommendations.py --sample 1000
  
  # ØªØ³Øª Ø¨Ø§ 100 Ú©Ø§Ø±Ø¨Ø±
  python generate_recommendations.py --sample 100
  
  # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
  python generate_recommendations.py
  python generate_recommendations.py --all
  
  # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ (Ø§Ø² command line)
  python generate_recommendations.py --users 123 456 789
  
  # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø´Ø®Øµ (Ø§Ø² ÙØ§ÛŒÙ„)
  python generate_recommendations.py --users-file user_ids.txt
  
  # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯
  python generate_recommendations.py --user 12345
        """
    )
    
    parser.add_argument(
        '--sample',
        type=int,
        default=None,
        metavar='N',
        help='ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (Ù…Ø«Ø§Ù„: 1000). Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ù†Ø´ÙˆØ¯ØŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.'
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)'
    )
    
    parser.add_argument(
        '--users',
        type=int,
        nargs='+',
        metavar='USER_ID',
        help='Ù„ÛŒØ³Øª ID Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ (Ù…Ø«Ø§Ù„: --users 123 456 789)'
    )
    
    parser.add_argument(
        '--user',
        type=int,
        metavar='USER_ID',
        help='ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± (Ù…Ø«Ø§Ù„: --user 12345)'
    )
    
    parser.add_argument(
        '--users-file',
        type=str,
        metavar='FILE',
        help='ÙØ§ÛŒÙ„ Ø­Ø§ÙˆÛŒ Ù„ÛŒØ³Øª user_id Ù‡Ø§ (Ù‡Ø± Ø®Ø· ÛŒÚ© user_id)'
    )
    
    parser.add_argument(
        '--top-k',
        type=int,
        default=20,
        metavar='K',
        help='ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 20)'
    )
    
    parser.add_argument(
        '--find-without-recommendations',
        action='store_true',
        help='Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡'
    )
    
    parser.add_argument(
        '--output-file',
        type=str,
        default=None,
        metavar='FILE',
        help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡ (Ù…Ø«Ø§Ù„: users_without_recs.csv)'
    )
    
    args = parser.parse_args()
    
    # Ø§Ú¯Ø± find-without-recommendations Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
    if args.find_without_recommendations:
        try:
            users_without = find_users_without_recommendations(
                limit=args.sample,
                output_file=args.output_file
            )
            if users_without:
                print(f"\nâœ… {len(users_without)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø¯ÙˆÙ† ØªÙˆØµÛŒÙ‡ Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
                print(f"\nØ¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©Ø§Ø±Ø¨Ø±Ø§Ù†:")
                print(f"python generate_recommendations.py --users {' '.join(map(str, users_without[:10]))}")
                if len(users_without) > 10:
                    print(f"   (ÙÙ‚Ø· 10 Ú©Ø§Ø±Ø¨Ø± Ø§ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯)")
            else:
                print("\nâœ… Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªÙˆØµÛŒÙ‡ Ø¯Ø§Ø±Ù†Ø¯!")
            sys.exit(0)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
            sys.exit(1)
        except Exception as e:
            print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ arguments
    if args.user:
        # ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±
        user_ids = [args.user]
        try:
            main_for_specific_users(user_ids, top_k=args.top_k)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
            sys.exit(1)
        except Exception as e:
            print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    elif args.users:
        # Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² command line
        user_ids = args.users
        try:
            main_for_specific_users(user_ids, top_k=args.top_k)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
            sys.exit(1)
        except Exception as e:
            print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    elif args.users_file:
        # Ù„ÛŒØ³Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² ÙØ§ÛŒÙ„
        try:
            with open(args.users_file, 'r') as f:
                user_ids = [int(line.strip()) for line in f if line.strip() and not line.strip().startswith('#')]
            
            if not user_ids:
                print(f"âŒ Ù‡ÛŒÚ† user_id Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ {args.users_file} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                sys.exit(1)
            
            print(f"ğŸ“„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {len(user_ids)} user_id Ø§Ø² ÙØ§ÛŒÙ„ {args.users_file}")
            try:
                main_for_specific_users(user_ids, top_k=args.top_k)
            except KeyboardInterrupt:
                print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
                sys.exit(1)
            except Exception as e:
                print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
                import traceback
                traceback.print_exc()
                sys.exit(1)
        except FileNotFoundError:
            print(f"âŒ ÙØ§ÛŒÙ„ {args.users_file} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            sys.exit(1)
        except ValueError as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† user_id Ø§Ø² ÙØ§ÛŒÙ„: {e}")
            sys.exit(1)
    else:
        # Ø­Ø§Ù„Øª Ø¹Ø§Ø¯ÛŒ (Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÛŒØ§ sample)
        sample_size = None if args.all else args.sample
        
        try:
            main(sample_size=sample_size)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
            sys.exit(1)
        except Exception as e:
            print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

