#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª:
1. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ØŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø³ÙØ§Ø±Ø´Ø§Øª Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
2. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Matomo Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ parquet Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
3. Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
4. Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªÙˆØµÛŒÙ‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
5. Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ parquet Ùˆ Redis Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""
from __future__ import annotations
import datetime as dt
import glob
import logging
import os
from collections import defaultdict
from pathlib import Path
from typing import List, Dict

import numpy as np
import polars as pl
from sqlalchemy import text

from dataframe_loader import get_engine, load_order_items
from hybrid_recommender import HybridRecommender
from models import Product, ProductInteraction, User
from object_loader import load_products, load_users
from settings import load_config

# ØªÙ†Ø¸ÛŒÙ… logger
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_users_from_db() -> pl.DataFrame:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª DataFrame"""
    engine = get_engine()
    sql = text("""
        SELECT id, email, 
               CONCAT(COALESCE(first_name, ''), ' ', COALESCE(last_name, '')) as name,
               created_at
        FROM users
        ORDER BY id
    """)
    
    with engine.connect() as conn:
        rows = [dict(row) for row in conn.execute(sql).mappings()]
    
    if not rows:
        return pl.DataFrame()
    
    return pl.DataFrame(rows)


def load_products_from_db() -> pl.DataFrame:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ ØµÙˆØ±Øª DataFrame"""
    engine = get_engine()
    sql = text("""
        SELECT id, title, slug, sku, sale_price, stock_quantity, 
               status, published_at, seller_id, category_id
        FROM products
        WHERE deleted_at IS NULL AND status = 1
        ORDER BY id
    """)
    
    with engine.connect() as conn:
        rows = [dict(row) for row in conn.execute(sql).mappings()]
    
    if not rows:
        return pl.DataFrame()
    
    return pl.DataFrame(rows)


def create_user_product_interactions(order_items_df: pl.DataFrame) -> List[ProductInteraction]:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù„ÛŒØ³Øª ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª"""
    interactions = []
    
    if order_items_df.is_empty():
        return interactions
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹â€ŒØªØ±
    for row in order_items_df.iter_rows(named=True):
        interaction = ProductInteraction(
            user_id=row['order_user_id'],
            product_id=row['product_id'],
            interaction_type='purchase',
            timestamp=row['order_created_at'],
            value=float(row['total_price'])
        )
        interactions.append(interaction)
    
    logger.info(f"Extracted {len(interactions)} purchase interactions")
    return interactions


def load_matomo_product_popularity() -> Dict[int, float]:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Matomo"""
    cfg = load_config()
    pageviews_files = sorted(glob.glob(
        os.path.join(cfg.output_dir, "matomo_pageviews_*.parquet")
    ))
    
    if not pageviews_files:
        logger.warning("Matomo pageviews file not found")
        return {}
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ÙØ§ÛŒÙ„
    latest_file = pageviews_files[-1]
    df = pl.read_parquet(latest_file)
    
    product_popularity = {}
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØµÙØ­Ø§Øª Ù…Ø­ØµÙˆÙ„ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª
    if 'label' in df.columns and 'nb_visits' in df.columns:
        product_rows = df.filter(pl.col('label') == 'product')
        
        for row in product_rows.iter_rows(named=True):
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ product_id Ø§Ø² URL ÛŒØ§ label
            # Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± URLâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø¯Ø§Ø±Ø¯
            # ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ú©Ù„ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
            popularity_score = float(row['nb_visits'])
            product_popularity[0] = popularity_score  # Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
    
    logger.info("Matomo popularity data loaded")
    return product_popularity


def generate_recommendations_for_all_users(
    recommender: HybridRecommender,
    users_df: pl.DataFrame,
    top_k: int = 20,
    sample_size: int = None
) -> pl.DataFrame:
    """
    ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    
    Args:
        recommender: Ù…Ø¯Ù„ ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø±
        users_df: DataFrame Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        top_k: ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        sample_size: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (None = Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†)
    """
    
    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ sample Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡
    if sample_size and sample_size < len(users_df):
        users_df = users_df.head(sample_size)
        logger.warning(f"Test mode: Only processing first {sample_size} users")
    
    recommendations_data = []
    
    logger.info(f"Starting recommendation generation for {len(users_df)} users...")
    
    # Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
    total_users = len(users_df)
    users_with_recommendations = 0
    users_without_recommendations = 0
    
    for idx, row in enumerate(users_df.iter_rows(named=True), 1):
        user_id = row['id']
        
        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª
        if idx % 100 == 0 or idx == total_users:
            logger.info(f"Processing user {idx}/{total_users} (User ID: {user_id})...")
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            recommendations = recommender.get_recommendations(user_id, top_k)
            
            if recommendations:
                users_with_recommendations += 1
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª
                for rank, rec in enumerate(recommendations, 1):
                    recommendations_data.append({
                        'user_id': user_id,
                        'product_id': rec.product_id,
                        'score': rec.score,
                        'rank': rank,
                        'confidence': rec.confidence,
                        'reason': rec.reason,
                        'collaborative_details': rec.collaborative_details,
                        'generated_at': dt.datetime.now()
                    })
            else:
                users_without_recommendations += 1
                
        except Exception as e:
            users_without_recommendations += 1
            if idx <= 10:  # ÙÙ‚Ø· 10 Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
                logger.warning(f"Error for user {user_id}: {e}")
    
    logger.info(
        f"Summary: {users_with_recommendations} users with recommendations, "
        f"{users_without_recommendations} without. "
        f"Total recommendations: {len(recommendations_data)}"
    )
    
    if not recommendations_data:
        logger.error("No recommendations generated!")
        return pl.DataFrame()
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
    recommendations_df = pl.DataFrame(recommendations_data)
    
    return recommendations_df


def save_recommendations(recommendations_df: pl.DataFrame, output_dir: str) -> str:
    """Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ parquet"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"user_recommendations_{timestamp}.parquet")
    
    recommendations_df.write_parquet(output_file)
    logger.info(f"Recommendations saved to: {output_file}")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø³Ø®Ù‡ CSV Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø­Øªâ€ŒØªØ±
    csv_file = output_file.replace('.parquet', '.csv')
    recommendations_df.write_csv(csv_file)
    logger.info(f"CSV version saved to: {csv_file}")
    
    return output_file


def print_sample_recommendations(recommendations_df: pl.DataFrame, products_df: pl.DataFrame, n_users: int = 5):
    """Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
    if recommendations_df.is_empty():
        return
    
    # ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹
    products_dict = {}
    for row in products_df.iter_rows(named=True):
        products_dict[row['id']] = row['title']
    
    print(f"\n{'='*80}")
    print(f"Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {n_users} Ú©Ø§Ø±Ø¨Ø± Ø§ÙˆÙ„:")
    print(f"{'='*80}\n")
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ user_id
    unique_users = recommendations_df['user_id'].unique().sort()[:n_users]
    
    for user_id in unique_users:
        user_recs = recommendations_df.filter(pl.col('user_id') == user_id).sort('rank')
        
        print(f"Ú©Ø§Ø±Ø¨Ø± {user_id} - {len(user_recs)} ØªÙˆØµÛŒÙ‡:")
        print("-" * 80)
        
        # Ù†Ù…Ø§ÛŒØ´ 5 ØªÙˆØµÛŒÙ‡ Ø§ÙˆÙ„
        for row in user_recs.head(5).iter_rows(named=True):
            product_title = products_dict.get(row['product_id'], f"Ù…Ø­ØµÙˆÙ„ {row['product_id']}")
            print(f"  {row['rank']}. {product_title}")
            print(f"     Ø§Ù…ØªÛŒØ§Ø²: {row['score']:.4f} | Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {row['confidence']:.2f}")
            print(f"     Ø¯Ù„ÛŒÙ„: {row['reason'][:100]}...")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª collaborative Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            if 'collaborative_details' in row and row['collaborative_details']:
                print(f"     Ø¬Ø²Ø¦ÛŒØ§Øª: {row['collaborative_details'][:150]}...")
        
        print()


def main(sample_size: int = None):
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
    
    Args:
        sample_size: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (None = Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†)
    """
    print("="*80)
    print("Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª")
    if sample_size:
        print(f"ğŸ§ª Ø­Ø§Ù„Øª ØªØ³Øª - {sample_size} Ú©Ø§Ø±Ø¨Ø±")
    else:
        print("ğŸš€ Ø­Ø§Ù„Øª Ú©Ø§Ù…Ù„ - Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†")
    print("="*80)
    print()
    
    cfg = load_config()
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    print("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    users_df = load_users_from_db()
    if users_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ø±Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    print(f"âœ… {len(users_df)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    products_df = load_products_from_db()
    if products_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    print(f"âœ… {len(products_df)} Ù…Ø­ØµÙˆÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    # 3. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª (Ø¢Ø®Ø± 180 Ø±ÙˆØ²)
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÙØ§Ø±Ø´Ø§Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³...")
    end_date = dt.date.today()
    start_date = end_date - dt.timedelta(days=180)  # 6 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡
    
    order_items_df = load_order_items(start_date, end_date)
    if order_items_df.is_empty():
        print("âš ï¸  Ù‡ÛŒÚ† Ø³ÙØ§Ø±Ø´ÛŒ Ø¯Ø± 180 Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        print("   ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø³ÙØ§Ø±Ø´Ø§Øª...")
        # Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªÙ…Ø§Ù… Ø³ÙØ§Ø±Ø´Ø§Øª Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒÙ…
        start_date = dt.date(2020, 1, 1)
        order_items_df = load_order_items(start_date, end_date)
        
        if order_items_df.is_empty():
            print("âŒ Ù‡ÛŒÚ† Ø³ÙØ§Ø±Ø´ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯! Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø§Ø±Ø¯.")
            return
    
    print(f"âœ… {len(order_items_df)} Ø¢ÛŒØªÙ… Ø³ÙØ§Ø±Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    print(f"   Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {start_date} ØªØ§ {end_date}")
    
    # 4. Ø§ÛŒØ¬Ø§Ø¯ ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„
    print("\nğŸ”„ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ ØªØ¹Ø§Ù…Ù„Ø§Øª Ú©Ø§Ø±Ø¨Ø±-Ù…Ø­ØµÙˆÙ„...")
    interactions = create_user_product_interactions(order_items_df)
    
    if not interactions:
        print("âŒ Ù‡ÛŒÚ† ØªØ¹Ø§Ù…Ù„ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯!")
        return
    
    # 5. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø² Matomo (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    print("\nğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ø§Ø² Matomo...")
    matomo_popularity = load_matomo_product_popularity()
    
    # 6. ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
    print("\nğŸ”„ ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§...")
    users_list = []
    for row in users_df.iter_rows(named=True):
        from models import User
        users_list.append(User(
            id=row['id'],
            email=row.get('email'),
            name=row.get('name'),
            created_at=row.get('created_at')
        ))
    
    products_list = []
    for row in products_df.iter_rows(named=True):
        from models import Product
        products_list.append(Product(
            id=row['id'],
            title=row['title'],
            slug=row['slug'],
            sku=row['sku'],
            sale_price=float(row['sale_price'] or 0),
            stock_quantity=int(row['stock_quantity'] or 0),
            status='published' if row['status'] == 1 else 'draft',
            published_at=row.get('published_at'),
            seller_id=row.get('seller_id'),
            category_id=row.get('category_id')
        ))
    
    # 7. Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡
    print("\nğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡...")
    print("   Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯...")
    
    recommender = HybridRecommender()
    
    # ØªÙ†Ø¸ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ
    recommender.users = users_list
    recommender.products = products_list
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ØªØ¹Ø§Ù…Ù„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ user_id
    user_interactions = defaultdict(list)
    for interaction in interactions:
        user_interactions[interaction.user_id].append(interaction)
    
    recommender.user_interactions = dict(user_interactions)
    
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ ØªØ¹Ø§Ù…Ù„: {len(user_interactions)}")
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    try:
        from collaborative_filtering import train_collaborative_model
        from content_based_filtering import train_content_based_model
        
        print("   ğŸ”¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Collaborative Filtering...")
        recommender.collaborative_model = train_collaborative_model(interactions)
        
        print("   ğŸ”¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Content-Based Filtering...")
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Sparse Matrix Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
        recommender.content_model = train_content_based_model(
            products_list, 
            user_interactions,
            use_sparse=True,  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Sparse Matrix
            max_similar_products=50  # Ø­Ø¯Ø§Ú©Ø«Ø± 50 Ù…Ø­ØµÙˆÙ„ Ù…Ø´Ø§Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø­ØµÙˆÙ„
        )
        
        print("âœ… Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯!")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 8. ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    if sample_size:
        print(f"\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ {sample_size} Ú©Ø§Ø±Ø¨Ø± (Ù†Ù…ÙˆÙ†Ù‡ ØªØ³Øª)...")
    else:
        print("\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†...")
    
    recommendations_df = generate_recommendations_for_all_users(
        recommender,
        users_df,
        top_k=20,  # 20 ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
        sample_size=sample_size
    )
    
    if recommendations_df.is_empty():
        print("âŒ Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯!")
        return
    
    # 9. Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print("\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§...")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ (backup)
    output_file = save_recommendations(recommendations_df, cfg.output_dir)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis
    try:
        from recommendation_storage import get_storage
        storage = get_storage()
        
        if storage.test_connection():
            stats = storage.store_batch_from_dataframe(recommendations_df, batch_size=1000)
            storage_stats = storage.get_stats()
            print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Redis:")
            print(f"   ØªØ¹Ø¯Ø§Ø¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡: {storage_stats['total_recommendations']}")
            print(f"   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø­Ø§ÙØ¸Ù‡: {storage_stats['memory_usage_mb']} MB")
        else:
            print("âš ï¸  Redis Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - ÙÙ‚Ø· ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except ImportError:
        print("âš ï¸  Ù…Ø§Ú˜ÙˆÙ„ recommendation_storage Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ - ÙÙ‚Ø· ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Redis: {e}")
        print("   âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")
    
    # 10. Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print_sample_recommendations(recommendations_df, products_df, n_users=5)
    
    # 11. Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
    print(f"\n{'='*80}")
    print("âœ… ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"{'='*80}")
    print(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {len(users_df)}")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª: {len(products_df)}")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ø³ÙØ§Ø±Ø´Ø§Øª: {len(order_items_df)}")
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {len(recommendations_df)}")
    print(f"   ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    import sys
    import argparse
    
    # ØªÙ†Ø¸ÛŒÙ… CLI arguments
    parser = argparse.ArgumentParser(
        description="ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:
  # ØªØ³Øª Ø¨Ø§ 1000 Ú©Ø§Ø±Ø¨Ø±
  python generate_recommendations.py --sample 1000
  
  # ØªØ³Øª Ø¨Ø§ 100 Ú©Ø§Ø±Ø¨Ø±
  python generate_recommendations.py --sample 100
  
  # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
  python generate_recommendations.py
  python generate_recommendations.py --all
        """
    )
    
    parser.add_argument(
        '--sample',
        type=int,
        default=None,
        metavar='N',
        help='ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª (Ù…Ø«Ø§Ù„: 1000). Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ù†Ø´ÙˆØ¯ØŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.'
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)'
    )
    
    args = parser.parse_args()
    
    # Ø§Ú¯Ø± --all Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ sample_size Ø±Ùˆ None Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    sample_size = None if args.all else args.sample
    
    try:
        main(sample_size=sample_size)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ÙØ±Ø¢ÛŒÙ†Ø¯ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

